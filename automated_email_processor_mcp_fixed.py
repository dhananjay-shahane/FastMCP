#!/usr/bin/env python3
"""
Automated Email Processor using MCP Server Tools and Ollama LLM ONLY

This MCP service:
1. Uses only LLM for all responses - NO fallback code
2. Executes data analysis via direct script execution
3. File operations through Path and direct access
4. All responses generated by Ollama LLM
"""

import asyncio
import logging
import sys
import subprocess
from datetime import datetime
from pathlib import Path
from typing import Dict, Any, Optional, List
import re

# Import MCP server components
from email_enhanced_server import email_handler, ollama_llm, EMAIL_CONFIG

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(sys.stdout)
    ]
)
logger = logging.getLogger('mcp_email_processor')

def extract_email_address(from_field: str) -> Optional[str]:
    """Extract email address from From field"""
    try:
        email_match = re.search(r'[\w\.-]+@[\w\.-]+\.\w+', from_field)
        return email_match.group(0) if email_match else None
    except Exception:
        return None

async def get_available_files() -> Dict[str, Any]:
    """Get available data and script files"""
    try:
        csv_files = []
        script_files = []
        
        # Get CSV files from data directory
        data_dir = Path(__file__).parent / "data"
        for csv_file in data_dir.glob('*.csv'):
            csv_files.append({
                'name': csv_file.name,
                'size': csv_file.stat().st_size,
                'available': True
            })
        
        # Get script files from scripts directory
        scripts_dir = Path(__file__).parent / "scripts"
        for script_file in scripts_dir.glob('*.py'):
            script_files.append(script_file.name)
        
        return {
            "success": True,
            "csv_files": csv_files,
            "script_files": script_files
        }
        
    except Exception as e:
        logger.error(f"Error getting files: {str(e)}")
        return {"success": False, "error": str(e)}

def analyze_llm_response(response_text: str, available_files: Dict[str, Any]) -> Dict[str, Any]:
    """Analyze LLM text response to extract intent"""
    response_lower = response_text.lower()
    
    # Check for visualization keywords
    viz_keywords = {
        'bar': 'bar_chart',
        'column': 'bar_chart',
        'line': 'line_graph',
        'trend': 'line_graph',
        'pie': 'pie_chart',
        'donut': 'pie_chart',
        'stats': 'custom_stats',
        'statistics': 'custom_stats'
    }
    
    visualization_type = None
    for keyword, viz_type in viz_keywords.items():
        if keyword in response_lower:
            visualization_type = viz_type
            break
    
    # Check for data file mentions
    data_file = None
    for file_info in available_files.get('csv_files', []):
        if file_info['name'].lower() in response_lower:
            data_file = file_info['name']
            break
    
    # Determine if this is a data request
    data_keywords = ['chart', 'graph', 'plot', 'visualization', 'analyze', 'data']
    is_data_request = any(keyword in response_lower for keyword in data_keywords)
    
    return {
        'requires_data_processing': is_data_request and visualization_type and data_file,
        'visualization_type': visualization_type,
        'data_file': data_file,
        'needs_clarification': is_data_request and (not visualization_type or not data_file),
        'intent': 'data_analysis' if is_data_request else 'general_inquiry'
    }

async def execute_data_analysis(analysis: Dict[str, Any]) -> Dict[str, Any]:
    """Execute data analysis script directly"""
    try:
        script_name = f"{analysis.get('visualization_type', 'bar_chart')}.py"
        data_file = analysis.get('data_file')
        
        if not data_file:
            return {"success": False, "error": "No data file specified"}
        
        script_path = Path(__file__).parent / "scripts" / script_name
        data_path = Path(__file__).parent / "data" / data_file
        
        if not script_path.exists():
            return {"success": False, "error": f"Script {script_name} not found"}
        
        if not data_path.exists():
            return {"success": False, "error": f"Data file {data_file} not found"}
        
        # Execute script
        result = subprocess.run(
            [sys.executable, str(script_path), str(data_path)],
            capture_output=True,
            text=True,
            timeout=300
        )
        
        if result.returncode == 0:
            # Find generated output files
            output_dir = Path(__file__).parent / "output"
            timestamp = datetime.now().strftime('%Y%m%d')
            generated_files = list(output_dir.glob(f'*{timestamp}*.png'))
            
            return {
                "success": True,
                "script_output": result.stdout,
                "generated_files": [str(f) for f in generated_files],
                "script_name": script_name,
                "data_file": data_file
            }
        else:
            return {
                "success": False,
                "error": result.stderr,
                "script_output": result.stdout
            }
        
    except Exception as e:
        logger.error(f"Error executing analysis: {str(e)}")
        return {"success": False, "error": str(e)}

async def process_email_with_llm_only(email_data: Dict[str, Any]) -> Dict[str, Any]:
    """Process email using ONLY LLM and direct execution - NO fallback responses"""
    try:
        sender = email_data.get('from', '')
        subject = email_data.get('subject', '')
        body = email_data.get('body', '')
        
        logger.info(f"üìß Processing email: {subject[:50]}...")
        logger.info(f"From: {sender}")
        
        # Extract sender email
        sender_email = extract_email_address(sender)
        if not sender_email:
            logger.warning(f"Could not extract sender email from: {sender}")
            return {"success": False, "error": "Invalid sender email"}
        
        # Get available files
        available_files = await get_available_files()
        
        # Get LLM analysis using enhanced context
        llm_context = f"""
Email Analysis Request:
From: {sender_email}
Subject: {subject}
Body: {body}

Available data files: {available_files['csv_files']}
Available scripts: {available_files['script_files']}

Analyze this email and determine:
1. Is this a data analysis/visualization request?
2. What type of visualization (bar, line, pie, stats)?
3. Which data file should be used?
4. What specific analysis is needed?
5. Does the request need clarification?

Be specific in your analysis.
"""
        
        llm_analysis_response = await ollama_llm.generate_response(body, llm_context)
        analysis = analyze_llm_response(llm_analysis_response, available_files)
        
        logger.info(f"ü§ñ LLM Analysis: {analysis}")
        
        # Process based on analysis
        if analysis.get('requires_data_processing', False):
            logger.info(f"‚öôÔ∏è Executing data analysis: {analysis['visualization_type']} on {analysis['data_file']}")
            
            # Execute data analysis
            execution_result = await execute_data_analysis(analysis)
            
            # Generate response with analysis results
            response_context = f"""
Email Response Generation:

Original request: {body}
From: {sender_email}
Subject: {subject}

Analysis completed:
- Data file: {analysis.get('data_file')}
- Visualization type: {analysis.get('visualization_type')}
- Execution result: {execution_result}

Generate a professional email response explaining what was done and mentioning any attached files.
Be helpful and specific about the analysis performed.
"""
            
            attachments = execution_result.get('generated_files', [])
        else:
            # Generate response for clarification or general inquiry
            response_context = f"""
Email Response Generation:

Original request: {body}
From: {sender_email}
Subject: {subject}

Analysis: {analysis}
Available files: {available_files}

Generate a helpful professional email response. If clarification is needed, ask specific questions.
If it's a general inquiry, explain available capabilities.
"""
            
            attachments = []
        
        # Generate email response using LLM
        llm_response_content = await ollama_llm.generate_response(response_context, "Generate professional email response:")
        
        logger.info(f"üìù Generated response length: {len(llm_response_content)} characters")
        
        # Send email using email handler
        response_subject = f"Re: {subject}" if not subject.startswith('Re:') else subject
        success = await email_handler.send_email(
            to_email=sender_email,
            subject=response_subject,
            body=llm_response_content,
            attachments=attachments
        )
        
        if success:
            logger.info(f"‚úÖ Email sent successfully to {sender_email}")
            if attachments:
                logger.info(f"üìé Included {len(attachments)} attachments")
        else:
            logger.error(f"‚ùå Failed to send email to {sender_email}")
        
        return {
            "success": success,
            "analysis": analysis,
            "response_content": llm_response_content,
            "attachments": attachments,
            "sender_email": sender_email
        }
        
    except Exception as e:
        logger.error(f"Error in LLM-only email processing: {str(e)}")
        return {"success": False, "error": str(e)}

async def check_and_process_emails() -> Dict[str, Any]:
    """Check and process emails using LLM only"""
    try:
        logger.info("üì® Checking for new emails...")
        
        # Get emails via email handler
        emails = await email_handler.get_filtered_emails(limit=5)
        
        if not emails:
            return {"success": True, "emails_processed": 0, "message": "No new emails"}
        
        processed_emails = []
        
        # Process each email using LLM only
        for email_data in emails:
            result = await process_email_with_llm_only(email_data)
            processed_emails.append(result)
            if result.get('success'):
                logger.info(f"‚úÖ Successfully processed email: {email_data.get('subject', '')[:50]}...")
            else:
                logger.error(f"‚ùå Failed to process email: {email_data.get('subject', '')[:50]}...")
            
        return {
            "success": True,
            "emails_processed": len(processed_emails),
            "results": processed_emails
        }
        
    except Exception as e:
        logger.error(f"Error checking emails: {str(e)}")
        return {"success": False, "error": str(e)}

async def start_llm_only_monitoring():
    """Start automated email monitoring using ONLY LLM and direct execution"""
    logger.info("üöÄ Starting LLM-ONLY email processing workflow...")
    logger.info(f"üìß Monitoring emails from: {EMAIL_CONFIG['allowed_sender']}")
    logger.info(f"‚è∞ Check interval: 30 seconds")
    logger.info("ü§ñ ALL responses generated by LLM - NO fallback code")
    logger.info("üîß Direct file operations and script execution")
    logger.info("Press Ctrl+C to stop...")
    
    try:
        processed_count = 0
        while True:
            check_result = await check_and_process_emails()
            if check_result.get('emails_processed', 0) > 0:
                processed_count += check_result['emails_processed']
                logger.info(f"üìä Total emails processed: {processed_count}")
            
            await asyncio.sleep(30)
            
    except KeyboardInterrupt:
        logger.info("\n‚èπÔ∏è  LLM email monitoring stopped by user")
        return {"success": True, "message": "Monitoring stopped", "processed_count": processed_count}
    except Exception as e:
        logger.error(f"Error in LLM monitoring: {str(e)}")
        return {"success": False, "error": str(e)}

async def main():
    """Main function to run LLM-only automated email processor"""
    try:
        await start_llm_only_monitoring()
    except Exception as e:
        logger.error(f"Fatal error in LLM email processor: {str(e)}")
        sys.exit(1)

if __name__ == "__main__":
    asyncio.run(main())